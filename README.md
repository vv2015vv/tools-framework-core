# tools-framework-core
这是一个非常简单的只用一个jar包搞定的分布式任务调度框架，使用门槛很低。


工作中可遇到过这样的场景：

	1、有很多定时的任务需要处理

	2、希望工具能够在多台服务器上同时运行

	3、希望待处理的数据能够在多台服务器上不重复的执行

	4、希望工具（再不修改配置项的情况下）也能高可用

	5、希望可以通过网页查看工具的运行状况

	等等


在尝试开发这个框架之前，当时用过TBSchedule，

但是因为TBSchedule资料比较少，用起来太费劲，出现问题后不方便查找，

所以基于当时自身项目的简单需求，开发了这个Tools-frame-work框架。

虽然后来发现开源框架Elastic-Job（当当ddframe的一部分）还不错，

不过我还是坚持开发下去了，作为学习的一个过程。

tools-frame-work支持的特性如下：

	1、非常简单，依赖也很少，只用一个jar包即可实现上述功能

	2、支持spring方式配置

	3、基于zookeeper的临时节点特性

	4、分布式锁：支持多实例启动后，单个实例处理任务，其他实例等待（简单的高可用场景）

	5、分布式任务调度：支持多实例启动后，多个实例同时处理任务，
		并且针对数据源进行平均拆分，保证多个实例不会重复处理数据
	
	6、支持jmx方式监控（目前暂无监控网页，而且开放的接口比较少）



	
	

实现原理介绍：

分布式锁：

	zookeeper本身自带分布式锁功能
	
分布式任务调度：

	1、工具实例启动后会在zk下注册任务节点（永久节点）
	
		在任务节点下注册机器信息节点（mac地址信息，临时节点）
		
	2、实例开始运行时，根据任务节点下的机器列表数量length和index来决定当前实例该处理哪些数据
	
		计算方式：id % len == index  其中id是你根据数据库表中的字段得到的一个数值
		
		可以是：自增长id，用户号码，会话id之类的都行
		
	3、拿到匹配的数据之后即可进行业务处理了（多线程并行处理）
	
	4、如果在运行过程中有节点新增或者删除，框架支持自动重新分片，如：
	
		原始有两个工具实例运行，那么length=2，index为0~1，数据源被分割为两片
		
		运行过程中发现业务量增长过快，运维新部署了一个工具实例，
		
			那么节点数量length=3，index为0~2，数据源被平均分为三片
			
		需要非常注意的是：
		
			为了避免临界点带来的数据重复处理，节点数量变化（新增/丢失）后，
			
			直到正在运行中的所有节点把当前执行周期的数据全部执行完成之后，才会重新分片
			
			具体实现逻辑依赖了一些状态参数的判断逻辑，详见代码。
			
			

			
代码示例：

	1、框架自带了测试方法
	
	2、使用时，将conf目录下的配置文件拷贝到resource目录下
	
	3、xml配置文件已配置好（基础环境如zk请提前配置）
	
	4、修改pom中的仓库地址
	
	5、执行TestMain即可看到
	
	6、如果开启了jmx，Client.java中是jmx的客户端测试方法
	
		详细信息在jconsole中可以看到
		